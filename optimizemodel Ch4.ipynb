{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/Users/liangwang/GitHub/DataAnalysis')\n",
    "sys.path.append(r'C:\\Users\\lwang\\Documents\\GitHub\\DataAnalysis2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import copy\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import math\n",
    "import datetime as dt\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly.colors\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy\n",
    "import importlib\n",
    "\n",
    "# ----- Internal Dependencies -------#\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(\"../..\")\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "from General import FileRead\n",
    "from General import AccuracyMetrics\n",
    "from General.GeneralFunctions import get_add_to_dict\n",
    "from General import TableManipulations\n",
    "from FeatureGeneration import GeneralFeatures\n",
    "from General import FileWrite\n",
    "\n",
    "from Plot.PdfHelper import PdfHelper\n",
    "from Plot.PlotMaker import PlotMaker\n",
    "# from Plot import Voltage_Plots\n",
    "from Plot import PlotFunctions\n",
    "# from Plot import AdHocPlots\n",
    "# from Plot import Sim_Plots\n",
    "\n",
    "# widget and notebook stuff\n",
    "from ipywidgets import interact, fixed\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\"\n",
    "\n",
    "import GlucoseModelsGen1\n",
    "import ErrorAndCostFunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\lwang\\OneDrive - Biolinq Inc\\Gen 1\\Algorithm Development\\Gen1 Modeling\\biolinq vs adj ref training updated.csv', engine='python')\n",
    "df_orig=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ErrorAndCostFunc' from 'c:\\\\Users\\\\lwang\\\\Documents\\\\GitHub\\\\for_test_LW\\\\ErrorAndCostFunc.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(GlucoseModelsGen1)\n",
    "importlib.reload(ErrorAndCostFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gluc_model_optim = GlucoseModelsGen1.GlucoseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_group = ['eBlinq19c', 'eBlinq20', 'eBlinq22 - Pre-Piv 1']\n",
    "test_group = ['eBlinq Pre-Piv 2']\n",
    "all_training_channel = ['Ch4']\n",
    "training_time_window = [0.083,5]\n",
    "training_chemistry = '2.6.11'\n",
    "model_output_valid_thresh = 0.5\n",
    "all_model_name = [\n",
    "    # 'sim_slope',\n",
    "    # 'sim_slope_constant_background',\n",
    "    'sim_slope_constant_compartment',\n",
    "    # 'sim_slope_linear_background',\n",
    "    # 'sim_slope_nonlinear_background',\n",
    "    # 'sim_slope_intercept_constant_background',\n",
    "    # 'sim_slope_intercept_constant_compartment',\n",
    "    # 'sim_slope_intercept_linear_background',\n",
    "    # 'sim_slope_intercept_nonlinear_background',\n",
    "    # 'fmm_constant_background',\n",
    "    # 'fmm_constant_compartment',\n",
    "    # 'fmm_linear_background',\n",
    "    # 'fmm_nonlinear_background'\n",
    "    ]\n",
    "all_err_func_name = [\n",
    "    # 'g_error_mse',\n",
    "    # 'g_error_mard',\n",
    "    # 'g_error_mard_weighted',\n",
    "    # 'g_error_median_ard',\n",
    "    # 'cur_error_mse',\n",
    "    # 'cur_error_mard',\n",
    "    # 'cur_error_mard_weighted',\n",
    "    'cur_error_median_ard'\n",
    "]\n",
    "all_results = {}\n",
    "all_results['metric'] = [\n",
    "    'mard_training',\n",
    "    'mard_weighted_training',\n",
    "    'mard_test',\n",
    "    'mard_weighted_test',\n",
    "    'ls_score_training',\n",
    "    'ls_slope_training',\n",
    "    'ls_intercept_training',\n",
    "    'ls_score_test',\n",
    "    'ls_slope_test',\n",
    "    'ls_intercept_test'\n",
    "]\n",
    "all_optim_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_channel in all_training_channel:\n",
    "    for model_name in all_model_name:\n",
    "        for err_func_name in all_err_func_name:\n",
    "            # training_channel = 'Ch1'\n",
    "            # model_name = 'sim_slope_linear_background'\n",
    "            model_gluc = f'{model_name}_gluc'\n",
    "            model_cur = f'{model_name}_cur'\n",
    "            bounds = f'{model_name}_bounds'\n",
    "            err_func = getattr(ErrorAndCostFunc,err_func_name)\n",
    "            this_result = []\n",
    "            df = df_orig.copy()\n",
    "            valid_training_index = df[df['Grouping'].isin(training_group) & df['time_from_start'].between(training_time_window[0],training_time_window[1]) & \n",
    "                                    df['Channel'].eq(training_channel) & df['is_model_output_valid'].ge(model_output_valid_thresh) &\n",
    "                                    df['Chemistry'].eq(training_chemistry)].index\n",
    "            # df_training_valid = df.loc[valid_training_index].reset_index(drop=True).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            df_training_valid = df.loc[valid_training_index].reset_index(drop=True)\n",
    "            valid_test_index = df[df['Grouping'].isin(test_group) & df['time_from_start'].between(training_time_window[0],training_time_window[1]) & \n",
    "                                    df['Channel'].eq(training_channel) & df['is_model_output_valid'].ge(model_output_valid_thresh) &\n",
    "                                    df['Chemistry'].eq(training_chemistry)].index\n",
    "            # df_test_valid = df.loc[valid_test_index].reset_index(drop=True).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            df_test_valid = df.loc[valid_test_index].reset_index(drop=True)\n",
    "\n",
    "            g_train = df_training_valid['Ref_value']\n",
    "            sim_train = df_training_valid['mag_1007']\n",
    "            i_train = df_training_valid['current']\n",
    "\n",
    "            g_test = df_test_valid['Ref_value']\n",
    "            sim_test = df_test_valid['mag_1007']\n",
    "            i_test = df_test_valid['current']\n",
    "\n",
    "            glucose_model = getattr(gluc_model_optim,model_gluc)\n",
    "            current_model = getattr(gluc_model_optim,model_cur)\n",
    "            bounds = getattr(gluc_model_optim,bounds)\n",
    "\n",
    "            if err_func_name.startswith('g'):\n",
    "                result= scipy.optimize.dual_annealing(err_func,bounds,args=(sim_train,i_train,g_train,glucose_model),maxiter=int(1e4))\n",
    "            elif err_func_name.startswith('cur'):\n",
    "                result= scipy.optimize.dual_annealing(err_func,bounds,args=(sim_train,i_train,g_train,current_model),maxiter=int(1e4))\n",
    "\n",
    "            # result_g_error_mse = scipy.optimize.dual_annealing(ErrorAndCostFunc.g_error_mse,bounds,args=(sim_train,i_train,g_train,glucose_model),maxiter=int(1e4))\n",
    "            # result_g_error_mard = scipy.optimize.dual_annealing(ErrorAndCostFunc.g_error_mard,bounds,args=(sim_train,i_train,g_train,glucose_model),maxiter=int(1e4))\n",
    "            # result_g_error_mard_weighted = scipy.optimize.dual_annealing(ErrorAndCostFunc.g_error_mard_weighted,bounds,args=(sim_train,i_train,g_train,glucose_model),maxiter=int(1e4))\n",
    "            # result_g_error_median_ard = scipy.optimize.dual_annealing(ErrorAndCostFunc.g_error_median_ard,bounds,args=(sim_train,i_train,g_train,glucose_model),maxiter=int(1e4))\n",
    "            # result_cur_error_mse = scipy.optimize.dual_annealing(ErrorAndCostFunc.cur_error_mse,bounds,args=(sim_train,i_train,g_train,current_model),maxiter=int(1e4))\n",
    "            # result_cur_error_mard = scipy.optimize.dual_annealing(ErrorAndCostFunc.cur_error_mard,bounds,args=(sim_train,i_train,g_train,current_model),maxiter=int(1e4))\n",
    "            # result_cur_error_mard_weighted = scipy.optimize.dual_annealing(ErrorAndCostFunc.cur_error_mard_weighted,bounds,args=(sim_train,i_train,g_train,current_model),maxiter=int(1e4))\n",
    "            # result_cur_error_median_ard = scipy.optimize.dual_annealing(ErrorAndCostFunc.cur_error_median_ard,bounds,args=(sim_train,i_train,g_train,current_model),maxiter=int(1e4))\n",
    "\n",
    "            # ErrorAndCostFunc.g_error_mse(result.x,sim_train,i_train,g_train,glucose_model)\n",
    "            # ErrorAndCostFunc.g_error_mse(result.x,sim_test,i_test,g_test,glucose_model)\n",
    "            this_result.append(ErrorAndCostFunc.g_error_mard(result.x,sim_train,i_train,g_train,glucose_model))\n",
    "            this_result.append(ErrorAndCostFunc.g_error_mard_weighted(result.x,sim_train,i_train,g_train,glucose_model))\n",
    "            this_result.append(ErrorAndCostFunc.g_error_mard(result.x,sim_test,i_test,g_test,glucose_model))\n",
    "            this_result.append(ErrorAndCostFunc.g_error_mard_weighted(result.x,sim_test,i_test,g_test,glucose_model))\n",
    "\n",
    "            reg_train = LinearRegression().fit(g_train.values.reshape(-1,1), glucose_model(sim_train,i_train,result.x).values)\n",
    "            this_result.append(reg_train.score(g_train.values.reshape(-1,1), glucose_model(sim_train,i_train,result.x).values))\n",
    "            this_result.append(reg_train.coef_)\n",
    "            this_result.append(reg_train.intercept_)           \n",
    "            # print(reg_train.score(g_train.values.reshape(-1,1), glucose_model(sim_train,i_train,result.x).values))\n",
    "            # print(reg_train.coef_)\n",
    "            # print(reg_train.intercept_)\n",
    "\n",
    "            reg_test = LinearRegression().fit(g_test.values.reshape(-1,1), glucose_model(sim_test,i_test,result.x).values)\n",
    "            this_result.append(reg_test.score(g_test.values.reshape(-1,1), glucose_model(sim_test,i_test,result.x).values))\n",
    "            this_result.append(reg_test.coef_)\n",
    "            this_result.append(reg_test.intercept_)\n",
    "            # print(reg_test.score(g_test.values.reshape(-1,1), glucose_model(sim_test,i_test,result.x).values))\n",
    "            # print(reg_test.coef_)\n",
    "            # print(reg_test.intercept_)\n",
    "\n",
    "            all_optim_params[f'{model_name}_{err_func_name}_{training_channel}'] = result.x\n",
    "            all_results[f'{model_name}_{err_func_name}_{training_channel}'] = this_result\n",
    "            results_df = pd.DataFrame.from_dict(all_results)\n",
    "            results_df.to_csv(r'C:\\Users\\lwang\\OneDrive - Biolinq Inc\\Gen 1\\Algorithm Development\\Gen1 Modeling\\results_13_models_ch4_candidate3.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>sim_slope_constant_compartment_cur_error_median_ard_Ch4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mard_training</td>\n",
       "      <td>25.892797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mard_weighted_training</td>\n",
       "      <td>31.362246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mard_test</td>\n",
       "      <td>24.869638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mard_weighted_test</td>\n",
       "      <td>29.328969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ls_score_training</td>\n",
       "      <td>0.767686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ls_slope_training</td>\n",
       "      <td>[1.0159823047199292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ls_intercept_training</td>\n",
       "      <td>2.290211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ls_score_test</td>\n",
       "      <td>0.765832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ls_slope_test</td>\n",
       "      <td>[0.9805961852152751]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ls_intercept_test</td>\n",
       "      <td>4.911256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   metric  \\\n",
       "0           mard_training   \n",
       "1  mard_weighted_training   \n",
       "2               mard_test   \n",
       "3      mard_weighted_test   \n",
       "4       ls_score_training   \n",
       "5       ls_slope_training   \n",
       "6   ls_intercept_training   \n",
       "7           ls_score_test   \n",
       "8           ls_slope_test   \n",
       "9       ls_intercept_test   \n",
       "\n",
       "  sim_slope_constant_compartment_cur_error_median_ard_Ch4  \n",
       "0                                          25.892797       \n",
       "1                                          31.362246       \n",
       "2                                          24.869638       \n",
       "3                                          29.328969       \n",
       "4                                           0.767686       \n",
       "5                               [1.0159823047199292]       \n",
       "6                                           2.290211       \n",
       "7                                           0.765832       \n",
       "8                               [0.9805961852152751]       \n",
       "9                                           4.911256       "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sim_slope_constant_compartment_cur_error_median_ard_Ch4': array([843.95453245, -22.37337731])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_optim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sim_slope_g_error_mard_weighted_Ch4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[43mall_optim_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msim_slope_g_error_mard_weighted_Ch4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sim_slope_g_error_mard_weighted_Ch4'"
     ]
    }
   ],
   "source": [
    "1/all_optim_params['sim_slope_g_error_mard_weighted_Ch4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #quadruple low glucose\n",
    "# df_training_valid=df_training_valid.append(df_training_valid[df_training_valid['Ref']<80]).reset_index(drop=True)\n",
    "# df_training_valid=df_training_valid.append(df_training_valid[df_training_valid['Ref']<80]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001, 2000.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: ['Maximum number of iteration reached']\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: 28.345808730150658\n",
       "       x: [ 9.794e+02]\n",
       "     nit: 10000\n",
       "    nfev: 74211\n",
       "    njev: 27101\n",
       "    nhev: 0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73852,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69121,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".datarunner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
