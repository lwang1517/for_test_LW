{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/liangwang/GitHub/DataAnalysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import copy\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import math\n",
    "import datetime as dt\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly.colors\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.interpolate import griddata\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "# ----- Internal Dependencies -------#\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(\"../..\")\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "from General import FileRead\n",
    "from General import AccuracyMetrics\n",
    "from General.GeneralFunctions import get_add_to_dict\n",
    "from General import TableManipulations\n",
    "from FeatureGeneration import GeneralFeatures\n",
    "from General import FileWrite\n",
    "\n",
    "from Plot.PdfHelper import PdfHelper\n",
    "from Plot.PlotMaker import PlotMaker\n",
    "# from Plot import Voltage_Plots\n",
    "from Plot import PlotFunctions\n",
    "# from Plot import AdHocPlots\n",
    "# from Plot import Sim_Plots\n",
    "\n",
    "# widget and notebook stuff\n",
    "from ipywidgets import interact, fixed\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/liangwang/Library/CloudStorage/OneDrive-Biolinq/Gen 1/Algorithm Development/Gen 1 Model Optimization/20240521/agg_mfg_ref_sample_df_from17.csv')\n",
    "df_orig=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_group = ['eBlinq17', 'eBlinq19a','eBlinq19b','eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqAcet','iBlinqFW231','iBlinqOverlay']\n",
    "# test_group = ['Pre-Piv-2-training']\n",
    "training_group = ['eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqFW231','iBlinqOverlay']\n",
    "test_group = ['Pre-Piv-2-training']\n",
    "training_time_window = [0.083,5]\n",
    "all_training_channel = ['1','3','4']\n",
    "# training_chemistry = '2.6.11'\n",
    "# test_chemistry = '2.6.11'\n",
    "iso_thresh = 25\n",
    "feature_hour_window = '8hr'\n",
    "feature_col = [\n",
    "    'time_from_start_featureGeneration',\n",
    "    f'ewm_average_{feature_hour_window}_iir_filt_model_output_s1_glucoseFeatureGeneration',\n",
    "    f'ewm_average_{feature_hour_window}_iir_filt_model_output_s3_glucoseFeatureGeneration',\n",
    "    f'ewm_average_{feature_hour_window}_iir_filt_model_output_s4_glucoseFeatureGeneration',\n",
    "    f'estimate_standard_deviation_{feature_hour_window}_iir_filt_model_output_s1_glucoseFeatureGeneration',\n",
    "    f'estimate_standard_deviation_{feature_hour_window}_iir_filt_model_output_s3_glucoseFeatureGeneration',\n",
    "    f'estimate_standard_deviation_{feature_hour_window}_iir_filt_model_output_s4_glucoseFeatureGeneration',\n",
    "]\n",
    "gluc_col = [\n",
    "    'model_output_s1_calculateGlucose','model_output_s3_calculateGlucose','model_output_s4_calculateGlucose',\n",
    "]\n",
    "\n",
    "gluc_ref_col = [\n",
    "    'Study','Sensor',\n",
    "    'retro_model_output_s1_calculateGlucose','retro_model_output_s3_calculateGlucose','retro_model_output_s4_calculateGlucose','cgm_adj','ysi','acck'\n",
    "]\n",
    "\n",
    "ground_truth_col = [\n",
    "    'retro_slope_s1','retro_intercept_s1',\n",
    "    'retro_slope_s3','retro_intercept_s3',\n",
    "    'retro_slope_s4','retro_intercept_s4',\n",
    "]\n",
    "all_cols = feature_col + gluc_col + gluc_ref_col + ground_truth_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_orig[all_cols].copy()\n",
    "# hypo_idx = df['cgm_adj'].le(100)\n",
    "# for ch_str in all_training_channel:\n",
    "#     df[f'ad_s{ch_str}'] = df[f'retro_model_output_s{ch_str}_calculateGlucose'].sub(df['cgm_adj']).abs()\n",
    "#     df[f'ard_s{ch_str}'] = df[f'ad_s{ch_str}'].div(df['cgm_adj']).mul(100)\n",
    "#     df[f'iso_s{ch_str}'] = df[f'ard_s{ch_str}']\n",
    "#     df.loc[hypo_idx,f'iso_s{ch_str}'] = df.loc[hypo_idx,f'ad_s{ch_str}']\n",
    "#     col_for_optim_no_ysi_acck = list(df.columns)\n",
    "#     col_for_optim_no_ysi_acck.remove('ysi')\n",
    "#     col_for_optim_no_ysi_acck.remove('acck')\n",
    "\n",
    "# training_index = df[df['Study'].isin(training_group) & df['time_from_start_featureGeneration'].between(training_time_window[0],training_time_window[1])].index\n",
    "# df_training = df.loc[training_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "# valid_training_index = df[df['Study'].isin(training_group) & df['time_from_start_featureGeneration'].between(training_time_window[0],training_time_window[1]) & \n",
    "#                         df[f'iso_s1'].le(iso_thresh) & df[f'iso_s3'].le(iso_thresh) & df[f'iso_s4'].le(iso_thresh)].index\n",
    "# df_training_valid = df.loc[valid_training_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "\n",
    "# x_train = df_training_valid[feature_col]\n",
    "# y_train = df_training_valid[ground_truth_col].to_numpy()\n",
    "# min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "# x_train_norm = min_max_scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has shape (4840579, 22)\n",
      "Training data has shape (2339834, 22)\n",
      "Ratio of training good data is 0.48337895115439705\n",
      "Test data has shape (982014, 22)\n",
      "Test data has shape (608644, 22)\n",
      "Ratio of good test data is 0.6197915711995959\n"
     ]
    }
   ],
   "source": [
    "df = df_orig[all_cols].copy()\n",
    "col_for_optim_no_ysi_acck = list(df.columns)\n",
    "col_for_optim_no_ysi_acck.remove('ysi')\n",
    "col_for_optim_no_ysi_acck.remove('acck')\n",
    "\n",
    "feature_name_avg_ch1 = f'ewm_average_{feature_hour_window}_iir_filt_model_output_s1_glucoseFeatureGeneration'\n",
    "feature_name_avg_ch1_lb = df[feature_name_avg_ch1].quantile(q=0.05)\n",
    "feature_name_avg_ch1_ub = df[feature_name_avg_ch1].quantile(q=0.95)\n",
    "feature_name_std_ch1 = f'estimate_standard_deviation_{feature_hour_window}_iir_filt_model_output_s1_glucoseFeatureGeneration'\n",
    "feature_name_std_ch1_lb = df[feature_name_std_ch1].quantile(q=0.05)\n",
    "feature_name_std_ch1_ub = df[feature_name_std_ch1].quantile(q=0.95)\n",
    "feature_name_avg_ch3 = f'ewm_average_{feature_hour_window}_iir_filt_model_output_s3_glucoseFeatureGeneration'\n",
    "feature_name_avg_ch3_lb = df[feature_name_avg_ch3].quantile(q=0.05)\n",
    "feature_name_avg_ch3_ub = df[feature_name_avg_ch3].quantile(q=0.95)\n",
    "feature_name_std_ch3 = f'estimate_standard_deviation_{feature_hour_window}_iir_filt_model_output_s3_glucoseFeatureGeneration'\n",
    "feature_name_std_ch3_lb = df[feature_name_std_ch3].quantile(q=0.05)\n",
    "feature_name_std_ch3_ub = df[feature_name_std_ch3].quantile(q=0.95)\n",
    "feature_name_avg_ch4 = f'ewm_average_{feature_hour_window}_iir_filt_model_output_s4_glucoseFeatureGeneration'\n",
    "feature_name_avg_ch4_lb = df[feature_name_avg_ch4].quantile(q=0.05)\n",
    "feature_name_avg_ch4_ub = df[feature_name_avg_ch4].quantile(q=0.95)\n",
    "feature_name_std_ch4 = f'estimate_standard_deviation_{feature_hour_window}_iir_filt_model_output_s4_glucoseFeatureGeneration'\n",
    "feature_name_std_ch4_lb = df[feature_name_std_ch4].quantile(q=0.05)\n",
    "feature_name_std_ch4_ub = df[feature_name_std_ch4].quantile(q=0.95)\n",
    "\n",
    "training_index = df[df['Study'].isin(training_group) & df['time_from_start_featureGeneration'].between(training_time_window[0],training_time_window[1])].index\n",
    "df_training = df.loc[training_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "valid_training_index = df[df['Study'].isin(training_group) & df['time_from_start_featureGeneration'].between(training_time_window[0],training_time_window[1]) & \n",
    "                        df[feature_name_avg_ch1].between(feature_name_avg_ch1_lb,feature_name_avg_ch1_ub) & \n",
    "                        df[feature_name_std_ch1].between(feature_name_std_ch1_lb,feature_name_std_ch1_ub) &\n",
    "                        df[feature_name_avg_ch3].between(feature_name_avg_ch3_lb,feature_name_avg_ch3_ub) &\n",
    "                        df[feature_name_std_ch3].between(feature_name_std_ch3_lb,feature_name_std_ch3_ub) &\n",
    "                        df[feature_name_avg_ch4].between(feature_name_avg_ch4_lb,feature_name_avg_ch4_ub) &\n",
    "                        df[feature_name_std_ch4].between(feature_name_std_ch4_lb,feature_name_std_ch4_ub) &\n",
    "                        df['retro_slope_s1'].between(0.5,1.5) & df['retro_intercept_s1'].between(-50,50) &\n",
    "                        df['retro_slope_s3'].between(0.5,1.5) & df['retro_intercept_s3'].between(-50,50) &\n",
    "                        df['retro_slope_s4'].between(0.5,1.5) & df['retro_intercept_s4'].between(-50,50)\n",
    "                        ].index\n",
    "df_training_valid = df.loc[valid_training_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "print(f'Training data has shape {df_training.shape}')\n",
    "print(f'Training data has shape {df_training_valid.shape}')\n",
    "good_data_ratio = len(df_training_valid)/len(df_training)\n",
    "print(f'Ratio of training good data is {good_data_ratio}')\n",
    "x_train = df_training_valid[feature_col]\n",
    "y_train = df_training_valid[ground_truth_col].to_numpy()\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "x_train_norm = min_max_scaler.fit_transform(x_train)\n",
    "\n",
    "test_index = df[df['Study'].isin(test_group) & df['time_from_start_featureGeneration'].between(training_time_window[0],training_time_window[1])].index\n",
    "df_test = df.loc[test_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "valid_test_index = df[df['Study'].isin(test_group) & df['time_from_start_featureGeneration'].between(training_time_window[0],training_time_window[1]) & \n",
    "                        df[feature_name_avg_ch1].between(feature_name_avg_ch1_lb,feature_name_avg_ch1_ub) & \n",
    "                        df[feature_name_std_ch1].between(feature_name_std_ch1_lb,feature_name_std_ch1_ub) &\n",
    "                        df[feature_name_avg_ch3].between(feature_name_avg_ch3_lb,feature_name_avg_ch3_ub) &\n",
    "                        df[feature_name_std_ch3].between(feature_name_std_ch3_lb,feature_name_std_ch3_ub) &\n",
    "                        df[feature_name_avg_ch4].between(feature_name_avg_ch4_lb,feature_name_avg_ch4_ub) &\n",
    "                        df[feature_name_std_ch4].between(feature_name_std_ch4_lb,feature_name_std_ch4_ub) &\n",
    "                        df['retro_slope_s1'].between(0.5,1.5) & df['retro_intercept_s1'].between(-50,50) &\n",
    "                        df['retro_slope_s3'].between(0.5,1.5) & df['retro_intercept_s3'].between(-50,50) &\n",
    "                        df['retro_slope_s4'].between(0.5,1.5) & df['retro_intercept_s4'].between(-50,50)\n",
    "                        ].index\n",
    "df_test_valid = df.loc[valid_test_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "print(f'Test data has shape {df_test.shape}')\n",
    "print(f'Test data has shape {df_test_valid.shape}')\n",
    "good_test_data_ratio = len(df_test_valid)/len(df_test)\n",
    "print(f'Ratio of good test data is {good_test_data_ratio}')\n",
    "x_test = df_test_valid[feature_col]\n",
    "x_test_norm = min_max_scaler.fit_transform(x_test)\n",
    "y_test = df_test_valid[ground_truth_col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing parameter 0\n",
      "The model today has MSE=0.9193229441352048\n",
      "The self cal model has MSE=0.03353375277271236\n",
      "The model today on test has MSE=0.9434721182340603\n",
      "The self cal model on test has MSE=0.02882043218824899\n",
      "Optimizing parameter 1\n",
      "The model today has MSE=404.09625527221516\n",
      "The self cal model has MSE=38.3364787555681\n",
      "The model today on test has MSE=384.8329433277382\n",
      "The self cal model on test has MSE=386.0079922683138\n",
      "Optimizing parameter 2\n",
      "The model today has MSE=0.8700670865013446\n",
      "The self cal model has MSE=0.0516444276449655\n",
      "The model today on test has MSE=0.8788723484477182\n",
      "The self cal model on test has MSE=0.02290377589146346\n",
      "Optimizing parameter 3\n",
      "The model today has MSE=393.0014112074821\n",
      "The self cal model has MSE=42.556581042981826\n",
      "The model today on test has MSE=353.29151324257407\n",
      "The self cal model on test has MSE=336.4018987934296\n",
      "Optimizing parameter 4\n",
      "The model today has MSE=0.9185202128503553\n",
      "The self cal model has MSE=0.05480728017626186\n",
      "The model today on test has MSE=0.9586008770822891\n",
      "The self cal model on test has MSE=0.02403821111543605\n",
      "Optimizing parameter 5\n",
      "The model today has MSE=397.43742665005294\n",
      "The self cal model has MSE=32.86550978880366\n",
      "The model today on test has MSE=332.71599106374646\n",
      "The self cal model on test has MSE=369.81784726558027\n"
     ]
    }
   ],
   "source": [
    "self_cal_model_dict = {}\n",
    "for i in range(6): # [0,1]:\n",
    "    print(f'Optimizing parameter {i}')\n",
    "    self_cal_model = MLPRegressor(hidden_layer_sizes=(5,5),solver='sgd',alpha=1e-4,max_iter=int(1e4),tol=1e-6,learning_rate='adaptive',random_state=20240528)\n",
    "    self_cal_model.fit(x_train_norm,y_train[:,i])\n",
    "    predict_slope_intercept = self_cal_model.predict(x_train_norm)\n",
    "    mse_train_selfcal = np.mean((predict_slope_intercept - y_train[:,0])**2)\n",
    "    mse_train_today = np.mean(y_train[:,i]**2)\n",
    "    print(f'The model today has MSE={mse_train_today}')\n",
    "    print(f'The self cal model has MSE={mse_train_selfcal}')\n",
    "\n",
    "    predict_slope_intercept_test = self_cal_model.predict(x_test_norm)\n",
    "    mse_test_selfcal = np.mean((predict_slope_intercept_test - y_test[:,i])**2)\n",
    "    mse_test_today = np.mean(y_test[:,i]**2)\n",
    "    print(f'The model today on test has MSE={mse_test_today}')\n",
    "    print(f'The self cal model on test has MSE={mse_test_selfcal}')\n",
    "    self_cal_model_dict[f'self_cal_model_{i}'] = self_cal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MARD of ch1 glucose is 0.21157109367696464\n",
      "Training data MARD of ch1 selfcal glucose is 0.18547760017062262\n",
      "Training data MARD of ch1 retro glucose is 0.16063806619825907\n",
      "Test data MARD of ch1 glucose is 0.19695547916299005\n",
      "Test data MARD of ch1 selfcal glucose is 0.17146476923280263\n",
      "Test data MARD of ch1 retro glucose is 0.13405671217947096\n"
     ]
    }
   ],
   "source": [
    "ch1_slope_train = self_cal_model_dict['self_cal_model_0'].predict(x_train_norm)\n",
    "ch1_intercept_train = self_cal_model_dict['self_cal_model_1'].predict(x_train_norm)\n",
    "df_training_valid['model_output_s1_selfcal'] = df_training_valid['model_output_s1_calculateGlucose'].sub(ch1_intercept_train).div(ch1_slope_train)\n",
    "mard_ch1_train_selfcal = df_training_valid['model_output_s1_selfcal'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "mard_ch1_train_today = df_training_valid['model_output_s1_calculateGlucose'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "mard_ch1_train_retro = df_training_valid['retro_model_output_s1_calculateGlucose'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "print(f'Training data MARD of ch1 glucose is {mard_ch1_train_today}')\n",
    "print(f'Training data MARD of ch1 selfcal glucose is {mard_ch1_train_selfcal}')\n",
    "print(f'Training data MARD of ch1 retro glucose is {mard_ch1_train_retro}')\n",
    "ch1_slope_test = self_cal_model_dict['self_cal_model_0'].predict(x_test_norm)\n",
    "ch1_intercept_test = self_cal_model_dict['self_cal_model_1'].predict(x_test_norm)\n",
    "df_test_valid['model_output_s1_selfcal'] = df_test_valid['model_output_s1_calculateGlucose'].sub(ch1_intercept_test).div(ch1_slope_test)\n",
    "mard_ch1_test_selfcal = df_test_valid['model_output_s1_selfcal'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "mard_ch1_test_today = df_test_valid['model_output_s1_calculateGlucose'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "mard_ch1_test_retro = df_test_valid['retro_model_output_s1_calculateGlucose'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "print(f'Test data MARD of ch1 glucose is {mard_ch1_test_today}')\n",
    "print(f'Test data MARD of ch1 selfcal glucose is {mard_ch1_test_selfcal}')\n",
    "print(f'Test data MARD of ch1 retro glucose is {mard_ch1_test_retro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0830053, 46.8401   , 36.6114   , 42.1527   ,  5.79154  ,\n",
       "        5.88723  ,  5.97644  ])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MARD of ch3 glucose is 0.2225366095403253\n",
      "Training data MARD of ch3 selfcal glucose is 0.1894561146148285\n",
      "Training data MARD of ch3 retro glucose is 0.16345391185336255\n",
      "Test data MARD of ch3 glucose is 0.19537829743436028\n",
      "Test data MARD of ch3 selfcal glucose is 0.17138015184454383\n",
      "Test data MARD of ch3 retro glucose is 0.137533313099084\n"
     ]
    }
   ],
   "source": [
    "ch3_slope_train = self_cal_model_dict['self_cal_model_2'].predict(x_train_norm)\n",
    "ch3_intercept_train = self_cal_model_dict['self_cal_model_3'].predict(x_train_norm)\n",
    "df_training_valid['model_output_s3_selfcal'] = df_training_valid['model_output_s3_calculateGlucose'].sub(ch3_intercept_train).div(ch3_slope_train)\n",
    "mard_ch3_train_selfcal = df_training_valid['model_output_s3_selfcal'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "mard_ch3_train_today = df_training_valid['model_output_s3_calculateGlucose'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "mard_ch3_train_retro = df_training_valid['retro_model_output_s3_calculateGlucose'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "print(f'Training data MARD of ch3 glucose is {mard_ch3_train_today}')\n",
    "print(f'Training data MARD of ch3 selfcal glucose is {mard_ch3_train_selfcal}')\n",
    "print(f'Training data MARD of ch3 retro glucose is {mard_ch3_train_retro}')\n",
    "ch3_slope_test = self_cal_model_dict['self_cal_model_2'].predict(x_test_norm)\n",
    "ch3_intercept_test = self_cal_model_dict['self_cal_model_3'].predict(x_test_norm)\n",
    "df_test_valid['model_output_s3_selfcal'] = df_test_valid['model_output_s3_calculateGlucose'].sub(ch3_intercept_test).div(ch3_slope_test)\n",
    "mard_ch3_test_selfcal = df_test_valid['model_output_s3_selfcal'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "mard_ch3_test_today = df_test_valid['model_output_s3_calculateGlucose'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "mard_ch3_test_retro = df_test_valid['retro_model_output_s3_calculateGlucose'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "print(f'Test data MARD of ch3 glucose is {mard_ch3_test_today}')\n",
    "print(f'Test data MARD of ch3 selfcal glucose is {mard_ch3_test_selfcal}')\n",
    "print(f'Test data MARD of ch3 retro glucose is {mard_ch3_test_retro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MARD of ch4 glucose is 0.2113779375457251\n",
      "Training data MARD of ch4 selfcal glucose is 0.18534839065679082\n",
      "Training data MARD of ch4 retro glucose is 0.16258662897338938\n",
      "Test data MARD of ch4 glucose is 0.19349628958680995\n",
      "Test data MARD of ch4 selfcal glucose is 0.17145969506036488\n",
      "Test data MARD of ch4 retro glucose is 0.13784931008953544\n"
     ]
    }
   ],
   "source": [
    "ch4_slope_train = self_cal_model_dict['self_cal_model_4'].predict(x_train_norm)\n",
    "ch4_intercept_train = self_cal_model_dict['self_cal_model_5'].predict(x_train_norm)\n",
    "df_training_valid['model_output_s4_selfcal'] = df_training_valid['model_output_s4_calculateGlucose'].sub(ch4_intercept_train).div(ch4_slope_train)\n",
    "mard_ch4_train_selfcal = df_training_valid['model_output_s4_selfcal'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "mard_ch4_train_today = df_training_valid['model_output_s4_calculateGlucose'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "mard_ch4_train_retro = df_training_valid['retro_model_output_s4_calculateGlucose'].sub(df_training_valid['cgm_adj']).div(df_training_valid['cgm_adj']).abs().mean()\n",
    "print(f'Training data MARD of ch4 glucose is {mard_ch4_train_today}')\n",
    "print(f'Training data MARD of ch4 selfcal glucose is {mard_ch4_train_selfcal}')\n",
    "print(f'Training data MARD of ch4 retro glucose is {mard_ch4_train_retro}')\n",
    "ch4_slope_test = self_cal_model_dict['self_cal_model_4'].predict(x_test_norm)\n",
    "ch4_intercept_test = self_cal_model_dict['self_cal_model_5'].predict(x_test_norm)\n",
    "df_test_valid['model_output_s4_selfcal'] = df_test_valid['model_output_s4_calculateGlucose'].sub(ch4_intercept_test).div(ch4_slope_test)\n",
    "mard_ch4_test_selfcal = df_test_valid['model_output_s4_selfcal'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "mard_ch4_test_today = df_test_valid['model_output_s4_calculateGlucose'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "mard_ch4_test_retro = df_test_valid['retro_model_output_s4_calculateGlucose'].sub(df_test_valid['cgm_adj']).div(df_test_valid['cgm_adj']).abs().mean()\n",
    "print(f'Test data MARD of ch4 glucose is {mard_ch4_test_today}')\n",
    "print(f'Test data MARD of ch4 selfcal glucose is {mard_ch4_test_selfcal}')\n",
    "print(f'Test data MARD of ch4 retro glucose is {mard_ch4_test_retro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.29394231821411"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_valid[['model_output_s1_selfcal','model_output_s3_selfcal','model_output_s4_selfcal']].std(1).quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.869971580377985"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_valid[['model_output_s1_calculateGlucose','model_output_s3_calculateGlucose','model_output_s4_calculateGlucose']].std(1).quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.335525535464043"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_valid[['retro_model_output_s1_calculateGlucose','retro_model_output_s3_calculateGlucose','retro_model_output_s4_calculateGlucose']].std(1).quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_cal_model_temp = MLPRegressor(solver='sgd',alpha=1e-1,max_iter=int(1e4),tol=1e-6,learning_rate='adaptive',random_state=20240528,verbose=True)\n",
    "param_list = {\"hidden_layer_sizes\": [(10,),(10,10),(10,5,2),(2,5,10),(4,3,4),(3,2,3),(5,5),(5,)]}\n",
    "gridCV = GridSearchCV(estimator=self_cal_model_temp, param_grid=param_list,cv=10,verbose=True)\n",
    "gridCV.fit(x_train_norm,y_train[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gridCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "self_cal_model = MLPRegressor(hidden_layer_sizes=(1,),solver='sgd',alpha=0.1,max_iter=int(1e4),tol=1e-6,learning_rate='adaptive',random_state=20240528)\n",
    "self_cal_model.fit(x_train_norm,y_train[:,i])\n",
    "predict_slope_intercept = self_cal_model.predict(x_train_norm)\n",
    "mse_train_selfcal = np.mean((predict_slope_intercept - y_train[:,0])**2)\n",
    "mse_train_today = np.mean(y_train[:,i]**2)\n",
    "print(f'The model today has MSE={mse_train_today}')\n",
    "print(f'The self cal model has MSE={mse_train_selfcal}')\n",
    "\n",
    "predict_slope_intercept_test = self_cal_model.predict(x_test_norm)\n",
    "mse_test_selfcal = np.mean((predict_slope_intercept_test - y_test[:,i])**2)\n",
    "mse_test_today = np.mean(y_test[:,i]**2)\n",
    "print(f'The model today on test has MSE={mse_test_today}')\n",
    "print(f'The self cal model on test has MSE={mse_test_selfcal}')\n",
    "self_cal_model_dict[f'self_cal_model_{i}'] = self_cal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:,i].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_valid[feature_col].plot(y='ewm_average_8hr_iir_filt_model_output_s3_glucoseFeatureGeneration',kind='hist',bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_cal_model = MLPRegressor(hidden_layer_sizes=(10,10,10),solver='sgd',alpha=1e-4,max_iter=int(1e4),tol=1e-6,learning_rate='adaptive',random_state=20240528)\n",
    "self_cal_model.fit(x_train_norm,y_train[:,0])\n",
    "predict_slope_intercept = self_cal_model.predict(x_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_test_index = df[df['Study'].isin(test_group) & df['time_from_start_featureGeneration'].between(training_time_window[0],training_time_window[1]) & \n",
    "                        df[f'iso_s{ch_str}'].le(iso_thresh) & df[f'iso_s3'].le(iso_thresh) & df[f'iso_s4'].le(iso_thresh)].index\n",
    "df_test_valid = df.loc[valid_test_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "print(f'Test data has shape {df_test_valid.shape}')\n",
    "x_test = df_test_valid[feature_col]\n",
    "x_test_norm = min_max_scaler.fit_transform(x_test)\n",
    "y_test = df_test_valid[ground_truth_col].to_numpy()\n",
    "\n",
    "predict_slope_intercept_test = self_cal_model.predict(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_test[:,0])**2)\n",
    "np.mean((predict_slope_intercept_test - y_test[:,0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_cal_model.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_slope_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_cal_model.predict(x_train_norm[10000,].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_slope_intercept.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    print(f'Training data has shape {df_training.shape}')\n",
    "    print(f'Training data has shape {df_training_valid.shape}')\n",
    "    good_data_ratio = len(df_training_valid)/len(df_training)\n",
    "    print(f'Ratio of good data is {good_data_ratio}')\n",
    "    valid_test_index = df[df['Study'].isin(test_group) & df['time_from_start'].between(training_time_window[0],training_time_window[1]) & \n",
    "                            df[f'iso_s{ch_str}'].le(iso_thresh) & df['Chemistry'].eq(training_chemistry)].index\n",
    "    df_test_valid = df.loc[valid_test_index,col_for_optim_no_ysi_acck].dropna().reset_index(drop=True)\n",
    "    print(f'Test data has shape {df_test_valid.shape}')\n",
    "    g_train = df_training_valid['cgm_adj']\n",
    "    features_train = df_training_valid[['time_from_start',f'mag{ch_str}_1007']]\n",
    "    cur_train = df_training_valid[f'cur{ch_str}']\n",
    "\n",
    "    g_test = df_test_valid['cgm_adj']\n",
    "    features_test = df_test_valid[['time_from_start',f'mag{ch_str}_1007']]\n",
    "    cur_test = df_test_valid[f'cur{ch_str}']\n",
    "\n",
    "    result = scipy.optimize.dual_annealing(mard,params_bound,callback=callback_da,args=(g_train,cur_train,features_train,ch_str),maxiter=int(1e3))\n",
    "\n",
    "    this_result.append(mard(result.x,g_train,cur_train,features_train,ch_str))\n",
    "    this_result.append(mard(result.x,g_test,cur_test,features_test,ch_str))\n",
    "\n",
    "    params_dict = params_list_to_dict(result.x,ch_str)\n",
    "    g_hat_train, _ = glucose_model(cur_train,features_train,params_dict) \n",
    "    g_hat_test, _ = glucose_model(cur_test,features_test,params_dict) \n",
    "\n",
    "    reg_train = LinearRegression().fit(g_train.values.reshape(-1,1), g_hat_train.values)\n",
    "    this_result.append(reg_train.score(g_train.values.reshape(-1,1), g_hat_train.values))\n",
    "    this_result.append(reg_train.coef_)\n",
    "    this_result.append(reg_train.intercept_)           \n",
    "\n",
    "    reg_test = LinearRegression().fit(g_test.values.reshape(-1,1), g_hat_test.values)\n",
    "    this_result.append(reg_test.score(g_test.values.reshape(-1,1), g_hat_test.values))\n",
    "    this_result.append(reg_test.coef_)\n",
    "    this_result.append(reg_test.intercept_)\n",
    "\n",
    "    all_optim_params[f'channel_{ch_str}'] = params_dict\n",
    "    all_results[f'channel_{ch_str}'] = this_result\n",
    "    \n",
    "results_df = pd.DataFrame.from_dict(all_results)\n",
    "results_df.to_csv(r'C:\\Users\\lwang\\OneDrive - Biolinq Inc\\Gen 1\\Algorithm Development\\Gen 1 Model Optimization\\20240521\\optimize_time_varying_model.csv',header=True)\n",
    "with open (r'C:\\Users\\lwang\\OneDrive - Biolinq Inc\\Gen 1\\Algorithm Development\\Gen 1 Model Optimization\\20240521\\all_optim_params.p','wb') as fp:\n",
    "    pickle.dump(all_optim_params,fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r'C:\\Users\\lwang\\OneDrive - Biolinq Inc\\Gen 1\\Algorithm Development\\Gen 1 Model Optimization\\20240521\\all_optim_params.p','wb') as fp:\n",
    "    pickle.dump(all_optim_params,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (r'C:\\Users\\lwang\\OneDrive - Biolinq Inc\\Gen 1\\Algorithm Development\\Gen 1 Model Optimization\\20240521\\all_optim_params.p','rb') as fp:\n",
    "#     all_optim_params2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_optim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as dist\n",
    "dist_info_sim_slope = dist.gamma(a=16,loc=0,scale=1/7061)\n",
    "time_from_start = [0,0.08,0.25,0.5,1,2,5]\n",
    "sim_slope_sensitivity = 0 + 1*dist_info_sim_slope.cdf(time_from_start)\n",
    "print(sim_slope_sensitivity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "params_dict = params_list_to_dict(result.x,1)\n",
    "pp.pprint(params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params_list_to_dict(result.x,ch_str)\n",
    "g_train_hat, sensitivity = glucose_model(cur_train,features_train,params)    \n",
    "mard = g_train_hat.sub(g_train).abs().div(g_train).mean()\n",
    "error = g_train_hat.sub(g_train).mul(sensitivity).abs().div(g_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_slope = g_train.div(cur_train).div(features_train['mag1_1007']).mean()\n",
    "sim_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_simple = cur_train.mul(features_train['mag1_1007']).mul(sim_slope)\n",
    "g_simple.sub(g_train).abs().div(g_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_simple = LinearRegression().fit(g_train.values.reshape(-1,1), g_simple.values)\n",
    "print(reg_simple.score(g_train.values.reshape(-1,1), g_simple.values))\n",
    "print(reg_simple.coef_)\n",
    "print(reg_simple.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params_list_to_dict(result.x,ch_str)\n",
    "g_hat_train, _ = glucose_model(cur_train,features_train,params) \n",
    "g_hat_test, _ = glucose_model(cur_test,features_test,params) \n",
    "reg_train = LinearRegression().fit(g_train.values.reshape(-1,1), g_hat_train.values)\n",
    "print(reg_train.score(g_train.values.reshape(-1,1), g_hat_train.values))\n",
    "print(reg_train.coef_)\n",
    "print(reg_train.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".datarunner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
