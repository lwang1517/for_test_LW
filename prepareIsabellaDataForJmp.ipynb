{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\lwang\\Documents\\GitHub\\DataAnalysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import platform\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.mode.chained_assignment = None\n",
    "import copy\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import math\n",
    "import datetime as dt\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly.colors\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import signal \n",
    "from scipy import odr \n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "\n",
    "# ----- Internal Dependencies -------#\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(\"../..\")\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "from General import FileRead\n",
    "from General import AccuracyMetrics\n",
    "from General.GeneralFunctions import get_add_to_dict\n",
    "from General import TableManipulations\n",
    "from FeatureGeneration import GeneralFeatures\n",
    "from General import FileWrite\n",
    "\n",
    "from Plot.PdfHelper import PdfHelper\n",
    "from Plot.PlotMaker import PlotMaker\n",
    "# from Plot import Voltage_Plots\n",
    "from Plot import PlotFunctions\n",
    "# from Plot import AdHocPlots\n",
    "# from Plot import Sim_Plots\n",
    "\n",
    "# widget and notebook stuff\n",
    "from ipywidgets import interact, fixed\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biolinq_col_keep = ['Algo','Study','ms_since_boot','algo_state','algo_state_desc','rate_of_change','is_rate_of_change_valid',\n",
    "                    'time_from_start','biolinq','biolinq_s1','biolinq_s3','biolinq_s4','biolinq_no_blank','sensor_id','UTC_Time',\n",
    "                    'color_code','color_desc','cur1','cur3','cur4','deg1_103','mag1_103','deg3_103','mag3_103','deg4_103','mag4_103',                   \n",
    "                    'deg1_1007','mag1_1007','deg3_1007','mag3_1007','deg4_1007','mag4_1007','deg1_10000','mag1_10000','deg3_10000','mag3_10000','deg4_10000','mag4_10000',                   \n",
    "                    ]\n",
    "sensor_map_col_keep = [\n",
    "    'Subject ID','IV Arm','Self Apply','Location','Config','Tier','Sorting Tier','Chemistry','Sorting Tier mfg','Chemistry mfg','Lot','Build',\n",
    "    'Wafer Lot #','Wafer Type','Wafer Batch - #','Wafer Location','Cardinal','Quadrant','Edge Level','Outermost'\n",
    "]\n",
    "all_col_keep = biolinq_col_keep + sensor_map_col_keep\n",
    "\n",
    "match_biolinq_ysi = True\n",
    "match_biolinq_acck = True\n",
    "match_biolinq_Dexcom = False\n",
    "match_biolinq_Libre = False\n",
    "reference_setting = {\n",
    "    'ysi': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "        'value_lb': 0,\n",
    "        'value_ub': 900\n",
    "    },\n",
    "    'acck': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "        'value_lb': 10,\n",
    "        'value_ub': 600\n",
    "    },\n",
    "    'Libre': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "        'value_lb': 40,\n",
    "        'value_ub': 400\n",
    "    },\n",
    "    'Dexcom': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "        'value_lb': 40,\n",
    "        'value_ub': 400\n",
    "    }         \n",
    "}\n",
    "\n",
    "eval_Dexcom = True\n",
    "Evaluate_Dexcom_setting = {\n",
    "    'ysi': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "    },\n",
    "    'acck': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "    },        \n",
    "}\n",
    "\n",
    "eval_Libre = True\n",
    "Evaluate_Libre_setting = {\n",
    "    'ysi': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "    },\n",
    "    'acck': {\n",
    "        'time_to_match': 'UTC_Time',\n",
    "        'direction_to_match': 'forward',\n",
    "        'tol_to_match': '5min',\n",
    "    },    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_data_dict = {\n",
    "    # 'Isabella03':{\n",
    "    #     'data_root_path': r\"S:\\for Brandegee Assembler\\Output\\6b6d8c5_gModel_indexFix_cgmadj_mfg_info\",\n",
    "    #     'study_folder': ['eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqAcet','Pre-Piv-2-training','Pre-Piv-2-validation','eBlinqMayStudyCtrl','eBlinqJuneStudyCtrl']\n",
    "    # },        \n",
    "    # 'Isabella04':{\n",
    "    #     'data_root_path': r\"S:\\for Brandegee Assembler\\Output\\tree_libre2ysi_extra_gModel_all_mfg_info\",\n",
    "    #     'study_folder': ['eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqAcet','Pre-Piv-2-training','Pre-Piv-2-validation','eBlinqMayStudyCtrl','eBlinqJuneStudyCtrl']\n",
    "    # },   \n",
    "    'Isabella03_gModel_allData':{\n",
    "        'data_root_path': r\"S:\\for Brandegee Assembler\\Output\\tree_libre2ysi_extra_gModel_all_mfg_info\",\n",
    "        'study_folder': ['eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqAcet','Pre-Piv-2-training','Pre-Piv-2-validation','eBlinqMayStudyCtrl','eBlinqJuneStudyCtrl']\n",
    "    },    \n",
    "    # 'mfg_model1_Keith_mdl9':{\n",
    "    #     'data_root_path': r\"S:\\AlgorithmOutput\\mdl9\",\n",
    "    #     'study_folder': ['eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqAcet','Pre-Piv-2-training','Pre-Piv-2-validation','MayStudy','JuneStudy_ctrl']\n",
    "    # },   \n",
    "    # 'nn_one_allData_training':{\n",
    "    #     'data_root_path': r\"S:\\for Brandegee Assembler\\Output\\oneForAll_plus_robust_tree_AllData_ThirdAttempt\",\n",
    "    #     'study_folder': ['eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqAcet','Pre-Piv-2-training','Pre-Piv-2-validation','eBlinqMayStudyCtrl','eBlinqJuneStudyCtrl']\n",
    "    # },   \n",
    "    # 'nn_one_mdl9_training':{\n",
    "    #     'data_root_path': r\"S:\\for Brandegee Assembler\\Output\\oneForAll_plus_robust_tree_mdl9TrainingData_SecondAttempt\",\n",
    "    #     'study_folder': ['eBlinq19c','eBlinq20','eBlinq22','eBlinq23','eBlinq25','eBlinqRingOverlay&NiMNA','iBlinqAcet','Pre-Piv-2-training','Pre-Piv-2-validation','eBlinqMayStudyCtrl','eBlinqJuneStudyCtrl']\n",
    "    # },         \n",
    "}\n",
    "save_agg_biolinq_ref_df = True\n",
    "save_agg_biolinq_datastore = True\n",
    "save_agg_Dexcom_ref_df = True\n",
    "save_agg_Libre_ref_df = True\n",
    "folder_to_save = r'C:\\Users\\lwang\\Documents\\Simulation\\data for JMP'\n",
    "file_suffix = 'CompareNnModel2'\n",
    "agg_biolinq_ref_df_file_name = f'agg_biolinq_ref_df_{file_suffix}.csv'\n",
    "agg_biolinq_datastore_file_name = f'agg_biolinq_datastore_{file_suffix}.csv'\n",
    "agg_Dexcom_ref_df_file_name = f'agg_Dexcom_ref_df_{file_suffix}.csv'\n",
    "agg_Libre_ref_df_file_name = f'agg_Libre_ref_df_{file_suffix}.csv'\n",
    "agg_biolinq_ref_df_file_path = os.path.join(folder_to_save,agg_biolinq_ref_df_file_name)\n",
    "agg_biolinq_datastore_file_path = os.path.join(folder_to_save,agg_biolinq_datastore_file_name)\n",
    "agg_Dexcom_ref_df_file_path = os.path.join(folder_to_save,agg_Dexcom_ref_df_file_name)\n",
    "agg_Libre_ref_df_file_path = os.path.join(folder_to_save,agg_Libre_ref_df_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_agg_biolinq_ref_df = False\n",
    "head_agg_biolinq_datastore = False\n",
    "head_agg_Dexcom_ref_df = False\n",
    "head_agg_Libre_ref_df = False\n",
    "match_biolinq_ref = {}\n",
    "match_biolinq_ref['match_biolinq_ysi'] = match_biolinq_ysi\n",
    "match_biolinq_ref['match_biolinq_acck'] = match_biolinq_acck\n",
    "match_biolinq_ref['match_biolinq_Dexcom'] = match_biolinq_Dexcom\n",
    "match_biolinq_ref['match_biolinq_Libre'] = match_biolinq_Libre\n",
    "for algo,algo_info in algo_data_dict.items():\n",
    "    print(f'Processing data by algo: {algo}')\n",
    "    data_root_path = algo_info['data_root_path']\n",
    "    study_folder = algo_info['study_folder']\n",
    "    for study in study_folder:\n",
    "        print(f'Processing data from clinical trial: {study}')\n",
    "        study_full_path = os.path.join(data_root_path,study)\n",
    "        loaded_data = FileRead.load_pickle('alg_out.zip', study_full_path, as_dict=True)\n",
    "        all_sensor_data = loaded_data['all_sensor_data']\n",
    "        sensor_map_df = loaded_data['sensor_map_df']\n",
    "        all_subject_id = sensor_map_df['Subject ID'].unique()\n",
    "        subject_id_processed = []\n",
    "        for sensor in all_sensor_data.keys():\n",
    "            print(f'Processing data from sensor: {sensor}')\n",
    "            current_subject_id = sensor_map_df.loc[sensor_map_df['Sensor_Id']==sensor,'Subject ID'].to_string(index=False)\n",
    "            if current_subject_id in subject_id_processed:\n",
    "                subject_processed_already = True\n",
    "            else:\n",
    "                subject_id_processed.append(current_subject_id)\n",
    "                subject_processed_already = False\n",
    "            current_sensor_data = all_sensor_data[sensor].copy()\n",
    "            biolinq_exist = False\n",
    "            ref_exist = {}\n",
    "            ref_exist['acck_exist'] = False\n",
    "            ref_exist['ysi_exist'] = False\n",
    "            ref_exist['Libre_exist'] = False\n",
    "            ref_exist['Dexcom_exist'] = False\n",
    "            ref_df_dict = {}\n",
    "            biolinq_ref_df_dict = {}\n",
    "            if ('biolinq' in current_sensor_data.keys()) and ('biolinq_datastore' in current_sensor_data.keys()):\n",
    "                biolinq_exist = True\n",
    "                biolinq_df = current_sensor_data['biolinq'].copy()\n",
    "                biolinq_datastore = current_sensor_data['biolinq_datastore'].copy()\n",
    "                if biolinq_df.empty:\n",
    "                    biolinq_exist = False\n",
    "            \n",
    "            if not biolinq_exist:\n",
    "                continue\n",
    "            biolinq_df['Algo'] = algo\n",
    "            biolinq_df['Study'] = study\n",
    "            biolinq_df = biolinq_df.merge(right=sensor_map_df,how='left',left_on='sensor_id',right_on='Sensor_Id')\n",
    "            biolinq_datastore['Algo'] = algo\n",
    "            biolinq_datastore['Study'] = study\n",
    "            biolinq_datastore = biolinq_datastore.merge(right=sensor_map_df,how='left',left_on='sensor_id',right_on='Sensor_Id')\n",
    "\n",
    "            #Fill in desired columns with NaN\n",
    "            for col in all_col_keep:\n",
    "                if col not in biolinq_df.columns:\n",
    "                    biolinq_df[col]=None\n",
    "            #Fill in desired columns with NaN\n",
    "            for col in all_col_keep:\n",
    "                if col not in biolinq_datastore.columns:\n",
    "                    biolinq_datastore[col]=None                    \n",
    "                            \n",
    "            for this_ref_name,this_ref_setting in reference_setting.items():\n",
    "                if this_ref_name in current_sensor_data.keys():\n",
    "                    ref_exist[f'{this_ref_name}_exist'] = True\n",
    "                    ref_df_dict[f'{this_ref_name}_df'] = current_sensor_data[this_ref_name].copy()\n",
    "                    if ref_df_dict[f'{this_ref_name}_df'].empty:\n",
    "                        ref_exist[f'{this_ref_name}_exist'] = False\n",
    "                    else:\n",
    "                        ref_df_dict[f'{this_ref_name}_df'].rename(columns={this_ref_name:'ref_value'},inplace=True)\n",
    "                        ref_df_dict[f'{this_ref_name}_df']['ref_type'] = this_ref_name\n",
    "                        valid_idx = ref_df_dict[f'{this_ref_name}_df']['ref_value'].ge(this_ref_setting['value_lb']) \\\n",
    "                            & ref_df_dict[f'{this_ref_name}_df']['ref_value'].le(this_ref_setting['value_ub'])\n",
    "                        ref_df_dict[f'{this_ref_name}_df'] = ref_df_dict[f'{this_ref_name}_df'].loc[valid_idx,:]\n",
    "                        ref_df_dict[f'{this_ref_name}_df'].loc[:,'subject_id_ref'] = current_subject_id\n",
    "                if (not ref_exist[f'{this_ref_name}_exist']) or (not match_biolinq_ref[f'match_biolinq_{this_ref_name}']):\n",
    "                    continue\n",
    "                time_to_match = this_ref_setting['time_to_match']\n",
    "                direction_to_match = this_ref_setting['direction_to_match']\n",
    "                tol_to_match = this_ref_setting['tol_to_match']\n",
    "                biolinq_ref_df_dict[f'biolinq_{this_ref_name}_df'] = pd.merge_asof(left=ref_df_dict[f'{this_ref_name}_df'].dropna(subset=[time_to_match]).sort_values(by=time_to_match), right=biolinq_df[all_col_keep].dropna(subset=[time_to_match]).sort_values(by=time_to_match),\n",
    "                                            on=time_to_match, direction=direction_to_match, tolerance=pd.Timedelta(tol_to_match))\n",
    "\n",
    "                #Save matched pairs table into CSV per reference\n",
    "                if save_agg_biolinq_ref_df:\n",
    "                    if head_agg_biolinq_ref_df==False:\n",
    "                        biolinq_ref_df_dict[f'biolinq_{this_ref_name}_df'].to_csv(agg_biolinq_ref_df_file_path,mode='a',float_format='%g',index=False,header=True)\n",
    "                        head_agg_biolinq_ref_df=True\n",
    "                    else:\n",
    "                        biolinq_ref_df_dict[f'biolinq_{this_ref_name}_df'].to_csv(agg_biolinq_ref_df_file_path,mode='a',float_format='%g',index=False,header=False) \n",
    "\n",
    "            # Save datastore table into csv per sensor\n",
    "            if save_agg_biolinq_datastore:\n",
    "                if head_agg_biolinq_datastore==False:\n",
    "                    biolinq_datastore[all_col_keep].to_csv(agg_biolinq_datastore_file_path,mode='a',float_format='%g',index=False,header=True)\n",
    "                    head_agg_biolinq_datastore=True\n",
    "                else:\n",
    "                    biolinq_datastore[all_col_keep].to_csv(agg_biolinq_datastore_file_path,mode='a',float_format='%g',index=False,header=False)\n",
    "\n",
    "            Dexcom_ref_df_dict = {}\n",
    "            if eval_Dexcom and ref_exist['Dexcom_exist'] and (not subject_processed_already):\n",
    "                for this_ref_name,this_ref_setting in Evaluate_Dexcom_setting.items():\n",
    "                    if ref_exist[f'{this_ref_name}_exist']:\n",
    "                        time_to_match = this_ref_setting['time_to_match']\n",
    "                        direction_to_match = this_ref_setting['direction_to_match']\n",
    "                        tol_to_match = this_ref_setting['tol_to_match']\n",
    "                        Dexcom_ref_df_dict[f'Dexcom_{this_ref_name}_df'] = pd.merge_asof(left=ref_df_dict[f'{this_ref_name}_df'].dropna(subset=[time_to_match]).sort_values(by=time_to_match), right=ref_df_dict['Dexcom_df'].dropna(subset=[time_to_match]).sort_values(by=time_to_match),\n",
    "                                                    on=time_to_match, direction=direction_to_match, tolerance=pd.Timedelta(tol_to_match),suffixes=(None,'_Dexcom'))\n",
    "                        \n",
    "                        #Save matched pairs table into CSV per reference\n",
    "                        if save_agg_Dexcom_ref_df:\n",
    "                            if head_agg_Dexcom_ref_df==False:\n",
    "                                Dexcom_ref_df_dict[f'Dexcom_{this_ref_name}_df'].to_csv(agg_Dexcom_ref_df_file_path,mode='a',float_format='%g',index=False,header=True)\n",
    "                                head_agg_Dexcom_ref_df=True\n",
    "                            else:\n",
    "                                Dexcom_ref_df_dict[f'Dexcom_{this_ref_name}_df'].to_csv(agg_Dexcom_ref_df_file_path,mode='a',float_format='%g',index=False,header=False)       \n",
    "\n",
    "            Libre_ref_df_dict = {}\n",
    "            if eval_Libre and ref_exist['Libre_exist'] and (not subject_processed_already):\n",
    "                for this_ref_name,this_ref_setting in Evaluate_Libre_setting.items():\n",
    "                    if ref_exist[f'{this_ref_name}_exist']:\n",
    "                        time_to_match = this_ref_setting['time_to_match']\n",
    "                        direction_to_match = this_ref_setting['direction_to_match']\n",
    "                        tol_to_match = this_ref_setting['tol_to_match']\n",
    "                        Libre_ref_df_dict[f'Libre_{this_ref_name}_df'] = pd.merge_asof(left=ref_df_dict[f'{this_ref_name}_df'].dropna(subset=[time_to_match]).sort_values(by=time_to_match), right=ref_df_dict['Libre_df'].dropna(subset=[time_to_match]).sort_values(by=time_to_match),\n",
    "                                                    on=time_to_match, direction=direction_to_match, tolerance=pd.Timedelta(tol_to_match),suffixes=(None,'_Libre'))\n",
    "                        \n",
    "                        #Save matched pairs table into CSV per reference\n",
    "                        if save_agg_Libre_ref_df:\n",
    "                            if head_agg_Libre_ref_df==False:\n",
    "                                Libre_ref_df_dict[f'Libre_{this_ref_name}_df'].to_csv(agg_Libre_ref_df_file_path,mode='a',float_format='%g',index=False,header=True)\n",
    "                                head_agg_Libre_ref_df=True\n",
    "                            else:\n",
    "                                Libre_ref_df_dict[f'Libre_{this_ref_name}_df'].to_csv(agg_Libre_ref_df_file_path,mode='a',float_format='%g',index=False,header=False)                                                     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlgoVenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
