{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import copy\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "import math\n",
    "import datetime as dt\n",
    "from sklearn.metrics import r2_score\n",
    "import plotly.colors\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import signal \n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ----- Internal Dependencies -------#\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(\"../..\")\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "from General import FileRead\n",
    "from General import AccuracyMetrics\n",
    "from General.GeneralFunctions import get_add_to_dict\n",
    "from General import TableManipulations\n",
    "from FeatureGeneration import GeneralFeatures\n",
    "from General import FileWrite\n",
    "\n",
    "from Plot.PdfHelper import PdfHelper\n",
    "from Plot.PlotMaker import PlotMaker\n",
    "# from Plot import Voltage_Plots\n",
    "from Plot import PlotFunctions\n",
    "# from Plot import AdHocPlots\n",
    "# from Plot import Sim_Plots\n",
    "\n",
    "# widget and notebook stuff\n",
    "from ipywidgets import interact, fixed\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_folder = Path(r'C:\\Users\\elizabeth\\OneDrive - Biolinq\\Shared Documents\\Data\\Aggregate\\eblinqiblinq 14 - 19b\\all_data\\prospective_8S17_v14d_2022_5day')\n",
    "loaded_data = FileRead.load_pickle('alg_out_no_excel.zip', full_folder, as_dict=True)\n",
    "all_sensor_data = loaded_data['all_sensor_data']\n",
    "sensor_map_df = loaded_data['sensor_map_df'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfg_df=pd.read_excel(r'C:\\Users\\elizabeth\\OneDrive - Biolinq\\Shared Documents\\Data\\Aggregate\\eblinqiblinq 14 - 19b\\manufacturing data\\BLINQ MPI-29 TRENDING SENSOR DATA.xlsx',sheet_name='compiled sensor data',skiprows=7)\n",
    "mfg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_sims=pd.read_excel(r'C:\\Users\\elizabeth\\OneDrive - Biolinq\\Shared Documents\\Data\\Aggregate\\eblinqiblinq 14 - 19b\\manufacturing data\\benchsims.xlsx',usecols='B:K')\n",
    "bench_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features and aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_str = ['1','3','4']\n",
    "combination_paired_ch = list(combinations(ch_str,2))\n",
    "current_ch_str = '1'\n",
    "col_prefix = 'v14_s'\n",
    "col_suffix = '_model_output'\n",
    "cols_to_use = []\n",
    "for ch_str_iter in ch_str: cols_to_use.append(col_prefix+ch_str_iter+col_suffix)\n",
    "\n",
    "roll_win_size = 96\n",
    "roll_min_size_ratio = 0.5\n",
    "\n",
    "feature_name_base = {\n",
    "    'filtered': 'sg_filt_s',\n",
    "    'gluc_noise': 'roll_snr_s',\n",
    "    'gluc_var1_s': 'roll_std_s',\n",
    "    'gluc_var2_s': 'roll_diff_maxmin_s',\n",
    "    'gluc_var3_s': 'roll_iqr_s',\n",
    "    'gluc_mov_avg1_s': 'roll_mean_s',\n",
    "    'gluc_mov_avg2_s': 'roll_median_s',\n",
    "    'gluc_avg_s': 'expand_median_s',\n",
    "    'gluc_change1': 'magnitude_change_s',\n",
    "    'gluc_change2': 'trend_change_s',\n",
    "    'ch_bias': 'roll_mrd_8hr',\n",
    "    'ch_precision': 'roll_mard_8hr',\n",
    "    'ch_corr': 'roll_corr_8hr',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df=pd.DataFrame()\n",
    "# for sensor in all_sensor_data.keys():\n",
    "for sensor in ['31360030051', '31360030069', '31360030071', '31360020004', '31360020006', '31360020023', '31360020026', '31360020032', '31360020034', '31360020038', '31360020041']:\n",
    "    sensor_df=all_sensor_data[sensor]['biolinq']\n",
    "\n",
    "    ###calculate features###\n",
    "    \"\"\" Calculate the features Liang defined \"\"\"\n",
    "    sensor_df=sensor_df.rename(columns={'Time':'Biolinq_Time'})\n",
    "    for paired_ch in combination_paired_ch:\n",
    "        col_A = col_prefix+paired_ch[0]+col_suffix\n",
    "        col_B = col_prefix+paired_ch[1]+col_suffix\n",
    "        diff_cols = sensor_df[col_A] - sensor_df[col_B]\n",
    "        avg_cols = sensor_df[col_A].divide(2) + sensor_df[col_B].divide(2)\n",
    "        rd_cols = diff_cols.divide(avg_cols).multiply(100)\n",
    "        ard_cols = rd_cols.abs()\n",
    "        sensor_df[feature_name_base['ch_bias']+''.join(paired_ch)] = rd_cols.rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean()\n",
    "        sensor_df[feature_name_base['ch_precision']+''.join(paired_ch)] = ard_cols.rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean()\n",
    "        sensor_df[feature_name_base['ch_corr']+''.join(paired_ch)] = sensor_df[col_A].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).corr(sensor_df[col_B])\n",
    "\n",
    "    for current_ch_str in ch_str:\n",
    "        current_col = col_prefix+current_ch_str+col_suffix\n",
    "        not_current_ch_str = ch_str.copy()\n",
    "        not_current_ch_str.remove(current_ch_str)\n",
    "        not_current_col = []\n",
    "        for ch_str_iter in not_current_ch_str: not_current_col.append(col_prefix+ch_str_iter+col_suffix) \n",
    "            \n",
    "        current_model_output_filtered = pd.Series(signal.savgol_filter(sensor_df[current_col],24,2))\n",
    "        sensor_df[feature_name_base['filtered']+current_ch_str] = current_model_output_filtered\n",
    "        current_model_output_noise = sensor_df[current_col] - current_model_output_filtered\n",
    "        sensor_df[feature_name_base['gluc_noise']+current_ch_str] = sensor_df[current_col].pow(2).rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean().\\\n",
    "                            divide(current_model_output_noise.pow(2).rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean())\n",
    "\n",
    "        sensor_df[feature_name_base['gluc_var1_s']+current_ch_str] = sensor_df[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).std()\n",
    "        sensor_df[feature_name_base['gluc_var2_s']+current_ch_str] = sensor_df[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).max()-\\\n",
    "                                        sensor_df[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).min()\n",
    "        sensor_df[feature_name_base['gluc_var3_s']+current_ch_str] = sensor_df[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).quantile(0.75)-\\\n",
    "                                        sensor_df[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).quantile(0.25)\n",
    "\n",
    "        sensor_df[feature_name_base['gluc_mov_avg1_s']+current_ch_str] = sensor_df[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean()\n",
    "        sensor_df[feature_name_base['gluc_mov_avg2_s']+current_ch_str] = sensor_df[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).median()\n",
    "        sensor_df[feature_name_base['gluc_avg_s']+current_ch_str] = sensor_df[current_col].expanding().median()\n",
    "\n",
    "        sensor_df[feature_name_base['gluc_change1']+current_ch_str] = sensor_df[feature_name_base['gluc_mov_avg2_s']+current_ch_str].subtract(sensor_df[feature_name_base['gluc_avg_s']+current_ch_str])\n",
    "        sensor_df[feature_name_base['gluc_change2']+current_ch_str] = sensor_df[feature_name_base['gluc_change1']+current_ch_str].diff().rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).median()\n",
    "         \n",
    "    #create matched pairs and aggregate\n",
    "    sensor_agg=pd.DataFrame()\n",
    "    for ref in ['ysi','acck','Dexcom','Libre']:\n",
    "        if ref not in all_sensor_data[sensor].keys():\n",
    "            continue\n",
    "        ref_df=all_sensor_data[sensor][ref]\n",
    "\n",
    "        ###adjust ref###\n",
    "\n",
    "        ref_df=ref_df.rename(columns={ref:'Ref'})\n",
    "        ref_df=ref_df.rename(columns={'Time':'Ref_Time'})\n",
    "        ref_df['RefType']=ref\n",
    "        \n",
    "        \n",
    "        paired_df=pd.merge_asof(right=sensor_df.dropna(subset=['UTC_Time']).sort_values(by='UTC_Time'),left=ref_df.dropna(subset=['UTC_Time']).sort_values(by='UTC_Time'),on='UTC_Time',direction='nearest',tolerance=pd.Timedelta('5min'))\n",
    "        # paired_df=paired_df.dropna(subset=['Ref'])\n",
    "        # paired_df=paired_df.dropna(subset=['biolinq'])\n",
    "        \n",
    "        sensor_agg=sensor_agg.append(paired_df)\n",
    "    \n",
    "    aggregated_df=aggregated_df.append(sensor_agg)\n",
    "\n",
    "###calculate metrics###\n",
    "aggregated_df['ARD']=100*np.abs((aggregated_df['biolinq']-aggregated_df['Ref'])/aggregated_df['Ref'])\n",
    "aggregated_df['RD']=100*((aggregated_df['biolinq']-aggregated_df['Ref'])/aggregated_df['Ref'])\n",
    "aggregated_df['D']=(aggregated_df['biolinq']-aggregated_df['Ref'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(r'/Users/liangwang/Library/CloudStorage/OneDrive-Biolinq/Documents - Clinical Data Analysis/Data/Aggregate/eblinqiblinq 14 - 19b/all_data/prospective_8S17_v14d_2022_5day')\n",
    "loaded_data = FileRead.load_pickle('alg_out_no_excel.zip', data_folder, as_dict=True)\n",
    "all_sensor_data = loaded_data['all_sensor_data']\n",
    "sensor_map_df = loaded_data['sensor_map_df'].copy()\n",
    "mfg_df=pd.read_excel(r'/Users/liangwang/Library/CloudStorage/OneDrive-Biolinq/Documents - Clinical Data Analysis/Data/Aggregate/eblinqiblinq 14 - 19b/manufacturing data/BLINQ MPI-29 TRENDING SENSOR DATA.xlsx',sheet_name='compiled sensor data',skiprows=7)\n",
    "bench_sims=pd.read_excel(r'/Users/liangwang/Library/CloudStorage/OneDrive-Biolinq/Documents - Clinical Data Analysis/Data/Aggregate/eblinqiblinq 14 - 19b/manufacturing data/benchsims.xlsx',usecols='B:K')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_data.keys())\n",
    "all_sensor_id = list(loaded_data['all_sensor_data'].keys())\n",
    "print(all_sensor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id = all_sensor_id[1]\n",
    "print(sensor_id)\n",
    "sensor_data = loaded_data['all_sensor_data'][sensor_id]\n",
    "sensor_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biolinq_data = sensor_data['biolinq']\n",
    "ysi_data = sensor_data['ysi']\n",
    "acck_data = sensor_data['acck']\n",
    "Dexcom_data = sensor_data['Dexcom']\n",
    "Libre_data = sensor_data['Libre']\n",
    "biolinq_data.head(100)\n",
    "# ysi_data.head()\n",
    "# acck_data.head()\n",
    "# Dexcom_data.head()\n",
    "# Libre_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=4, cols=2,shared_xaxes=True,vertical_spacing = 0.01,subplot_titles=['Sensor: ' + sensor_id])\n",
    "fig = fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    height=1200,\n",
    "    legend_tracegroupgap=10\n",
    ")\n",
    "fig = fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    ")\n",
    "fig = fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    ")\n",
    "current_row = 1\n",
    "ysi_size= 10\n",
    "acck_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_str = ['1','3','4']\n",
    "current_ch_str = '1'\n",
    "col_prefix = 'v14_s'\n",
    "col_suffix = '_model_output'\n",
    "\n",
    "roll_win_size = 96\n",
    "roll_min_size_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = []\n",
    "for ch_str_iter in ch_str: cols_to_use.append(col_prefix+ch_str_iter+col_suffix) \n",
    "current_col = col_prefix+current_ch_str+col_suffix\n",
    "not_current_ch_str = ch_str.copy()\n",
    "not_current_ch_str.remove(current_ch_str)\n",
    "not_current_col = []\n",
    "for ch_str_iter in not_current_ch_str: not_current_col.append(col_prefix+ch_str_iter+col_suffix) \n",
    "\n",
    "current_model_output_filtered = pd.Series(signal.savgol_filter(biolinq_data[current_col],24,2))\n",
    "fig = fig.add_trace(go.Scatter(x=ysi_data['Time'],y=ysi_data['ysi'],name='YSI',legendgroup = '1',mode='markers',marker=dict(size=ysi_size,color='magenta',symbol='x')),row=current_row,col=1)\n",
    "fig = fig.add_trace(go.Scatter(x=acck_data['Time'],y=acck_data['acck'],name='Acck',legendgroup = '1',mode='markers',marker=dict(size=acck_size,color='red',symbol='circle',line=dict(color='black',width=1))),row=current_row,col=1)\n",
    "for other_col in not_current_col:\n",
    "    fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[other_col],name=other_col,legendgroup = '1',line=dict(width=1,color='lightgray')),row=current_row,col=1)\n",
    "fig = fig.add_trace(go.Scatter(x=Libre_data['Time'],y=Libre_data['Libre'],name='Libre',legendgroup = '1',mode='lines',line=dict(width=2,color='lime')),row=current_row,col=1)\n",
    "fig = fig.add_trace(go.Scatter(x=Dexcom_data['Time'],y=Dexcom_data['Dexcom'],name='Dexcom',legendgroup = '1',mode='lines',line=dict(width=2,color='lightgreen')),row=current_row,col=1)\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[current_col],mode='markers',name=current_col,legendgroup = '1',marker=dict(size=3,color='darkblue')),row=current_row,col=1)\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=current_model_output_filtered,name=current_col+'_filtered',legendgroup = '1',line=dict(width=2.5,color='lightblue')),row=current_row,col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_paired_ch = list(combinations(ch_str,2))\n",
    "for paired_ch in combination_paired_ch:\n",
    "    if current_ch_str in paired_ch:\n",
    "        col_A = col_prefix+paired_ch[0]+col_suffix\n",
    "        col_B = col_prefix+paired_ch[1]+col_suffix\n",
    "        # feature_name1 = 'Ard_'+''.join(paired_ch)\n",
    "        feature_name2 = 'roll_mrd_8hr'+''.join(paired_ch)\n",
    "        feature_name3 = 'roll_mard_8hr'+''.join(paired_ch)\n",
    "        diff_cols = biolinq_data[col_A] - biolinq_data[col_B]\n",
    "        avg_cols = biolinq_data[col_A].divide(2) + biolinq_data[col_B].divide(2)\n",
    "        rd_cols = diff_cols.divide(avg_cols).multiply(100)\n",
    "        ard_cols = rd_cols.abs()\n",
    "        # biolinq_data[feature_name1] = diff_cols.abs().divide(avg_cols).multiply(100)\n",
    "        biolinq_data[feature_name2] = rd_cols.rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean()\n",
    "        biolinq_data[feature_name3] = ard_cols.rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean()\n",
    "\n",
    "        feature_name4 = 'roll_corr_8hr_'+''.join(paired_ch)\n",
    "        biolinq_data[feature_name4] = biolinq_data[col_A].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).corr(biolinq_data[col_B])\n",
    "\n",
    "        # fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name1],name=feature_name1,legendgroup = '2'),row=2,col=1)\n",
    "        fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name2],name=feature_name2,legendgroup = '2'),row=2,col=1)\n",
    "        fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name3],name=feature_name3,legendgroup = '2'),row=2,col=1)\n",
    "        fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name4],name=feature_name4,legendgroup = '3'),row=3,col=1)\n",
    "\n",
    "current_model_output_noise = biolinq_data[current_col] - current_model_output_filtered\n",
    "feature_name5 = 'roll_snr_s' + current_ch_str\n",
    "biolinq_data[feature_name5] = biolinq_data[current_col].pow(2).rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean().\\\n",
    "                            divide(current_model_output_noise.pow(2).rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean())\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name5],name=feature_name5,legendgroup = '4'),row=4,col=1)\n",
    "\n",
    "feature_name6 = 'roll_std_s' + current_ch_str\n",
    "feature_name7 = 'roll_diff_max_min_s' + current_ch_str\n",
    "feature_name8 = 'roll_iqr_s' + current_ch_str\n",
    "biolinq_data[feature_name6] = biolinq_data[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).std()\n",
    "biolinq_data[feature_name7] = biolinq_data[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).max()-\\\n",
    "                                biolinq_data[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).min()\n",
    "biolinq_data[feature_name8] = biolinq_data[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).quantile(0.75)-\\\n",
    "                                biolinq_data[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).quantile(0.25)\n",
    "\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name6],name=feature_name6,legendgroup = '5'),row=1,col=2)\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name7],name=feature_name7,legendgroup = '5'),row=1,col=2)\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name8],name=feature_name8,legendgroup = '5'),row=1,col=2)\n",
    "\n",
    "feature_name9 = 'roll_mean_s' + current_ch_str\n",
    "feature_name10 = 'roll_median_s' + current_ch_str\n",
    "feature_name11 = 'expand_median_s' + current_ch_str\n",
    "biolinq_data[feature_name9] = biolinq_data[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).mean()\n",
    "biolinq_data[feature_name10] = biolinq_data[current_col].rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).median()\n",
    "biolinq_data[feature_name11] = biolinq_data[current_col].expanding().median()\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name9],name=feature_name9,legendgroup = '6'),row=2,col=2)\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name10],name=feature_name10,legendgroup = '6'),row=2,col=2)\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name11],name=feature_name11,legendgroup = '6'),row=2,col=2)\n",
    "\n",
    "feature_name12 = 'magnitude_change_' + current_ch_str\n",
    "feature_name13 = 'trend_change_' + current_ch_str\n",
    "biolinq_data[feature_name12] = biolinq_data[feature_name10].subtract(biolinq_data[feature_name11])\n",
    "biolinq_data[feature_name13] = biolinq_data[feature_name12].diff().rolling(roll_win_size,min_periods=int(roll_win_size*roll_min_size_ratio)).median()\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name12],name=feature_name12,legendgroup = '7'),row=3,col=2)\n",
    "fig = fig.add_trace(go.Scatter(x=biolinq_data['Time'],y=biolinq_data[feature_name13],name=feature_name13,legendgroup = '8'),row=4,col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biolinq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
